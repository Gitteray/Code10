header={
       "GET":url,
       "host":"suggestion.baidu.com",
       "Referer":"http://www.baidu.com/",
       "User-Agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.57 Safari/537.36",
       }
    proxy_handler = urllib2.ProxyHandler({'http': 'http://'+ip})
    #proxy_auth_handler = urllib2.ProxyBasicAuthHandler()
    #proxy_auth_handler.add_password('realm', 'host', 'username', 'password') //
    opener = urllib2.build_opener(proxy_handler)
    # This time, rather than install the OpenerDirector, we use it directly:
    #opener.open('http://www.example.com/login.html') //打开百度网址

    urllib2.install_opener(opener)
    req = urllib2.Request(url)
    for key in header:
        req.add_header(key,header[key])
        html=urllib2.urlopen(req).read()
        html1=re.findall("\"(.*?)\"",html)
        #output = open('output.txt','w')
        for item in html1:
            print item  //打出关键词的条目
            #output.write(item)
            #output.write("\n")
        #output.close()    
        #time.sleep(5) //时隔5秒后获取下一个关键词的搜索结果


